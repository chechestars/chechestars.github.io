<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[ubuntu 14.04 下单机安装 hadoop 2.7.2+scala 2.11.8+spark 2.0伪分布式教程]]></title>
    <url>%2F2017%2F07%2F27%2Fubuntu%2014.04%20%E4%B8%8B%E5%8D%95%E6%9C%BA%E5%AE%89%E8%A3%85%20hadoop%202.7.2%2Bscala%202.11.8%2Bspark%202.0%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[听说高大上的spark2.0版本发布啦，凑个热闹来安装一下。 本文安装方式及教程截图均基于ubuntu 14.04系统需要下载以下4个软件：说明：自己尝试发现手动下载这些软件的压缩包再解压到某目录下的方式比命令行稍快一点，后面也有命令行下载方式的说明。此种方式适用于习惯图形界面的童鞋。1.Hadoop-2.7.2.tar.gz 下载网址：http://www-eu.apache.org/dist/hadoop/common/hadoop-2.7.2/hadoop-2.7.2.tar.gz2.scala-2.11.8.tgz 下载网址：http://downloads.lightbend.com/scala/2.11.8/scala-2.11.8.tgz3.spark-2.0.0-bin-hadoop2.7.tgz 下载网址：http://spark.apache.org/downloads.html4.java下载网址：http://download.oracle.com/otn-pub/java/jdk/8u101-b13/jdk-8u101-linux-x64.tar.gz 一.安装java将java下载后手动解压到/home/che文件夹下（可采用右击压缩包，单击“提取”）在终端（可用Ctrl+Alt+T快捷键打开）中输入： 1sudo gedit /etc/profile 在打开的文本中添加：1234export JAVA_HOME=/home/che/jdk1.8.0_101/export JRE_HOME=/home/che/jdk1.8.0_101/jreexport PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATH 二.配置ssh localhost确保安装好ssh： 123sudo apt-get updatesudo apt-get install openssh-serversudo /etc/init.d/ssh start 生成并添加密钥： 1ssh-keygen -t rsa 12cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keyschmod 0600 ~/.ssh/authorized_keys 测试ssh localhost12ssh localhostexit 三.安装hadoop2.6.0将hadoop2.6.0下载然后手动解压到/home/che文件夹下【或者】执行：123cd /home/chewget http://www-eu.apache.org/dist/hadoop/common/hadoop-2.7.2/hadoop-2.7.2.tar.gztar -xzvf hadoop-2.7.2.tar.gz 编辑/etc/profile文件1sudo gedit /etc/profile 添加：12345678export HADOOP_HOME=/home/che/hadoop-2.7.2export HADOOP_INSTALL=$HADOOP_HOMEexport HADOOP_MAPRED_HOME=$HADOOP_HOMEexport HADOOP_COMMON_HOME=$HADOOP_HOMEexport HADOOP_HDFS_HOME=$HADOOP_HOMEexport YARN_HOME=$HADOOP_HOMEexport HADOOP_COMMON_LIB_NATIVE_DIR=$HADOOP_HOME/lib/nativeexport PATH=$PATH:$HADOOP_HOME/sbin:$HADOOP_HOME/bin 让其生效1source /etc/profile 编辑$HADOOP_HOME/etc/hadoop/hadoop-env.sh文件1sudo gedit $HADOOP_HOME/etc/hadoop/hadoop-env.sh 添加：1export JAVA_HOME=/home/che/jdk1.8.0_101/ 修改core-site.xml文件12cd $HADOOP_HOME/etc/hadoopsudo gedit core-site.xml 修改为：123456&lt;configuration&gt;&lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; 修改hdfs-site.xml文件1sudo gedit hdfs-site.xml 修改为（第一个是dfs的备份数目，单机用1份就行，后面两个是namenode和datanode的目录）：12345678910111213141516&lt;configuration&gt;&lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;1&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.name.dir&lt;/name&gt; &lt;value&gt;file:///home/che/hadoopdata/hdfs/namenode&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.data.dir&lt;/name&gt; &lt;value&gt;file:///home/che/hadoopdata/hdfs/datanode&lt;/value&gt;&lt;/property&gt;&lt;/configuration&gt; 修改mapred-site.xml.template1sudo gedit mapred-site.xml.template 修改为：123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 修改yarn-site.xml1sudo gedit yarn-site.xml 修改为：123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 初始化hadoop：1hdfs namenode -format 启动1$HADOOP_HOME/sbin/start-all.sh 停止1$HADOOP_HOME/sbin/stop-all.sh 检查WebUI，浏览器打开端口8088：http://localhost:8088 其他端口说明：port 8088: cluster and all applicationsport 50070: Hadoop NameNodeport 50090: Secondary NameNodeport 50075: DataNodehadoop运行后可使用jps命令查看,得到结果： 四.安装scala将scala下载后手动解压文件到/home/che文件夹【或者】执行：12cd /home/chetar -xzvf scala-2.11.8.tgz 在/etc/profile文件的末尾添加环境变量：1sudo gedit /etc/profile 添加：12export SCALA_HOME=/home/che/scala-2.11.8export PATH=$SCALA_HOME/bin:$PATH 保存并更新/etc/profile：1source /etc/profile 查看是否成功：1scala -version 五.安装spark下载spark手动解压安装包到/home/che文件夹下【或者】执行：123cd /home/chetar -xzvf spark-2.0.0-bin-hadoop2.7.tgzmv spark-2.0.0-bin-hadoop2.7 spark-2.0.0 打开/etc/profile文件1sudo gedit /etc/profile 在/etc/profile文件的末尾添加环境变量：12export SPARK_HOME=/home/che/spark-2.0.0export PATH=$SPARK_HOME/bin:$PATH 保存并更新/etc/profile：1source /etc/profile 在conf目录下复制并重命名spark-env.sh.template为spark-env.sh：123cd $SPARK_HOME/confcp spark-env.sh.template spark-env.shsudo gedit spark-env.sh 添加：1234export JAVA_HOME=/home/che/jdk1.8.0_101export SCALA_HOME=/home/che/scala-2.11.9export SPARK_MASTER_IP=masterexport SPARK_WORKER_MEMORY=4G 启动spark12$SPARK_HOME/sbin/start-all.shjps 可以打开http://localhost:8080/看worker情况（只有启动之后才能看到） 可以看到有一个worker，现在就可以愉快的玩耍spark啦！！！1$SPARK_HOME/bin/run-example SparkPi 看看你有没有得到:1Pi is roughly 3.14716 （当时运行出来一大串代码，最后找了半天这个结果在代码中间隐藏着） 参考网址：http://blog.tomgou.xyz/spark-160-dan-ji-an-zhuang-pei-zhi.htmlhttp://blog.csdn.net/stark_summer/article/details/43495623 转载请注明文章来源及作者：会飞的星星]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>scala</tag>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Win10 64位下GPU版本MXNet+Tensorflow 1.3.0的安装]]></title>
    <url>%2F2017%2F07%2F23%2FWin10%2064%E4%BD%8D%E4%B8%8BGPU%E7%89%88%E6%9C%ACMXNet%2BTensorflow%201.3.0%E7%9A%84%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[说明：本文记录时间为2017.7.23。在此时Tensorflow在Win下的安装要求为系统64位且Python版本为3.5（现已经支持py 3.6），MXNet在Win下只支持Python 2。更新说明：在8月19日发布了Tensorflow1.3.0后，cudnn支持6.0而不再支持5.1，所以一定要选对版本哦。 一.安装Anaconda由于Mxnet在win下只支持Python 2，tensorflow在win下只支持Python 3.5，所以选择Anaconda创建Python2和3共存的环境。 ###1. 安装Anaconda 2 作为主环境 ###a. 下载Anaconda。官网速度较慢，可考虑使用清华镜像 https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/ b. 安装。默认安装位置为C:\Users\Che\Anaconda2，注意需如下图所示两项都选才能将其添加到环境变量。 2. 安装Anaconda 3 环境有两种方式安装Anaconda 3环境 ●conda创建 在CMD命令行中使用如下代码创建名为mxnet的环境，使用的是Python 3.5版本。1conda create -n py3 python=3.5 anaconda 优点：简单；缺点：联网下载包，速度慢。 ●手动下载并安装（这种安装方式在以后的安装包的时候可能会存在问题，不建议） 下载Anaconda3 安装Anaconda3的安装目录必须选在C:\Users\Che\Anaconda2\envs子目录下，名称“py3”可以自己取，并加在路径的最后。安装过程中注意一定取消取消掉第一个√，避免将Anaconda3添加到系统PATH路径下。 优点：安装时间短。 验证两种方式的Anaconda3环境创建成功与否： a. 在CMD里面直接输入12pythonexit() 会看到启动Python 2.7，然后退出。b.使用如下代码切换到Python 3123activate py3pythonexit() 此处的”py3”即之前Python3安装目录文件夹的名字。使用activate py3命令之后，在命令行前面会出现一个[py3]标记，此时使用任何的python命令都是在Python 3.5下进行的。使用如下命令可取消激活Python 3。1deactivate py3 二.安装CUDA和cuDNN因为我们要安装GPU版本，所以需要 CUDA 和 cuDNN 的支持。 请先在 这里确认你的显卡支持 CUDA。 如果以上条件符合，那么可以开始从各自官网下载 CUDA 8.0 和 cuDNN V6.0的安装包。 CUDA: https://developer.nvidia.com/cuda-downloads cuDNN: https://developer.nvidia.com/rdp/cudnn-download (需要注册) 安装CUDA。双击执行安装程序，安装后会自动添加系统变量。测试安装是否成功：在CMD中输入“nvcc -V”。 安装cuDNN。解压后的另一个压缩文件文件继续解压，放到任何一个目录下（此处为D:\cuda），然后把所放的那个目录添加到Path 环境变量里。将下面这些文件复制到相应位置：D:\cuda\bin\cudnn64_6.dll —&gt; C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0\bin D:\cuda\include\cudnn.h —&gt; C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0\include D:\cuda\lib\x64\cudnn.lib —&gt; C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v8.0\lib\x64 三.安装MXNet参考网址：https://stankirdey.com/2017/07/04/upgrading-mxnet-from-0-9-to-0-10-on-windows-10/下载准备：https://github.com/yajiedesign/mxnet/releases 上的两个文件，如图所示： VC14 – prebuildbase_win10_x64_vc14.7z 20170721_mxnet_x64_vc14_gpu.7z1.将下载的两个文件解压到D:\mxnet\，将之前下载的cuDNN压缩包解压到D:\mxnet\3rdparty\cudnn 2.添加环境变量MXNET_HOME，值为D:\mxnet 3.添加环境变量Path的值：%MXNET_HOME%\lib;%MXNET_HOME%\3rdparty\cudnn\bin;%MXNET_HOME%\3rdparty\cudart;%MXNET_HOME%\3rdparty\opencv;%MXNET_HOME%\3rdparty\vc;%MXNET_HOME%\3rdparty\gnuwin;%MXNET_HOME%\3rdparty\openblas\bin; 说明：第2,3步在原文中是使用setupenv.cmd文件来执行，但自己操作中发现Path值的路径出现多加斜杠的错误，所以这里采用了手动操作的方法。 4.添加环境变量PYTHONPATH，值为：D:\mxnet\python（这一步是因为自己后续操作发现在其他位置无法导入mxnet模块，所以这里添加python的搜索路径） 5.在CMD下进入D:\mxnet\python，执行1python setup.py install 测试安装成功： 到这里MXNet就安装好啦。Enjoy！ 四.安装TensorflowTensorflow官网：https://www.tensorflow.org/install/install_windows ●准备工作： 确保Python版本是3.5且系统为64位（非常重要）。 确保pip版本最新，可用python -m pip install -U pip 在CMD中升级pip 。 确保安装Visual Studio 2015 或者 2013 或者 2010。 确保已安装cuda和cuDNN。 ●安装方式：由于我们是在py3子环境下安装了Python3，所以需先使用activate py3进入子环境。进入后，可使用官网提供的两种方式进行安装。 pip 1pip3 install --upgrade tensorflow-gpu Anaconda 1pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.2.1-cp35-cp35m-win_amd64.whl 注意： 在安装Tensorflow时很可能会出现 “Cannot remove entries from nonexistent file c:\program files\anaconda3\lib\site-packages\easy-install.pth” 的报错，这是setuptools版本太低导致。解决方法：pip install –upgrade –ignore-installed setuptools]]></content>
      <categories>
        <category>深度学习</category>
      </categories>
      <tags>
        <tag>MXNet</tag>
        <tag>Tensorflow</tag>
      </tags>
  </entry>
</search>
